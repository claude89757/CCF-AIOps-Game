#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
@author: claude89757
@date: 2025-06-29
@description: å·¥å…·æ‰§è¡Œå™¨
"""

import json
import logging
from typing import Dict, Any, Callable
from datetime import datetime
from dataclasses import dataclass

from ..config import AgentConfig
from .validator import ParameterValidator
from .error_handler import ErrorHandler
from ..tools import preview_parquet_in_pd, get_data_from_parquet


@dataclass
class ToolCall:
    """å·¥å…·è°ƒç”¨æ•°æ®ç»“æ„"""
    name: str
    parameters: Dict[str, Any]


class ToolExecutor:
    """å·¥å…·æ‰§è¡Œå™¨"""
    
    def __init__(self, config: AgentConfig, loggers: Dict[str, logging.Logger]):
        self.config = config
        self.loggers = loggers
        self.validator = ParameterValidator(config)
        self.error_handler = ErrorHandler(config)
        self.tools = self._register_tools()
    
    def _register_tools(self) -> Dict[str, Callable]:
        """æ³¨å†Œå¯ç”¨çš„å·¥å…·å‡½æ•°"""
        return {
            "preview_parquet_in_pd": preview_parquet_in_pd,
            "get_data_from_parquet": get_data_from_parquet,
            "attempt_completion": self._handle_completion
        }
    
    def _handle_completion(self, result: str) -> Dict[str, Any]:
        """å¤„ç†å®Œæˆä»»åŠ¡çš„å·¥å…·è°ƒç”¨"""
        try:
            self.loggers['diagnosis'].info("å°è¯•å®Œæˆä»»åŠ¡ï¼Œè§£æç»“æœ...")
            
            # å°è¯•è§£æJSONç»“æœ
            result_data = json.loads(result)
            
            # éªŒè¯å¿…éœ€å­—æ®µ
            required_fields = ["uuid", "component", "reason", "time", "reasoning_trace"]
            for field in required_fields:
                if field not in result_data:
                    error_msg = f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}"
                    self.loggers['diagnosis'].error(error_msg)
                    return {
                        "status": "error",
                        "error": error_msg,
                        "raw_result": result
                    }
            
            # éªŒè¯reasoning_traceæ ¼å¼
            if not isinstance(result_data["reasoning_trace"], list):
                error_msg = "reasoning_traceå¿…é¡»æ˜¯æ•°ç»„"
                self.loggers['diagnosis'].error(error_msg)
                return {
                    "status": "error",
                    "error": error_msg,
                    "raw_result": result
                }
            
            for i, step in enumerate(result_data["reasoning_trace"]):
                if not isinstance(step, dict) or "step" not in step or "action" not in step or "observation" not in step:
                    error_msg = f"reasoning_traceç¬¬{i+1}æ­¥æ ¼å¼é”™è¯¯ï¼Œéœ€è¦åŒ…å«stepã€actionã€observationå­—æ®µ"
                    self.loggers['diagnosis'].error(error_msg)
                    return {
                        "status": "error",
                        "error": error_msg,
                        "raw_result": result
                    }
            
            self.loggers['diagnosis'].info("ä»»åŠ¡å®Œæˆï¼Œç»“æœæ ¼å¼éªŒè¯é€šè¿‡")
            return {
                "status": "completed",
                "result": result_data,
                "message": "æ•…éšœè¯Šæ–­å®Œæˆï¼Œç»“æœæ ¼å¼éªŒè¯é€šè¿‡"
            }
            
        except json.JSONDecodeError as e:
            error_msg = f"JSONè§£æå¤±è´¥: {str(e)}"
            self.loggers['diagnosis'].error(error_msg)
            return {
                "status": "error",
                "error": error_msg,
                "raw_result": result
            }
    
    def execute_tool(self, tool_call: ToolCall, case_error_logger: logging.Logger = None) -> Dict[str, Any]:
        """
        å¢å¼ºçš„å·¥å…·æ‰§è¡Œï¼Œæ”¯æŒæ™ºèƒ½é”™è¯¯å¤„ç†å’Œè‡ªåŠ¨å›é€€
        
        Args:
            tool_call: å·¥å…·è°ƒç”¨å¯¹è±¡
            case_error_logger: æ¡ˆä¾‹ç‰¹å®šçš„é”™è¯¯æ—¥å¿—è®°å½•å™¨
            
        Returns:
            å·¥å…·æ‰§è¡Œç»“æœ
        """
        start_time = datetime.now()
        
        if tool_call.name not in self.tools:
            error_result = {
                "error": f"æœªçŸ¥å·¥å…·: {tool_call.name}",
                "available_tools": list(self.tools.keys())
            }
            self._log_tool_execution(tool_call, error_result)
            return error_result
        
        # å‚æ•°éªŒè¯å’Œä¿®æ­£
        try:
            validated_params = self.validator.validate_tool_parameters(tool_call.name, tool_call.parameters)
            tool_call.parameters = validated_params
        except Exception as e:
            self.loggers['tool'].warning(f"å‚æ•°éªŒè¯å¤±è´¥: {e}")
        
        try:
            tool_func = self.tools[tool_call.name]
            result = tool_func(**tool_call.parameters)
            
            execution_time = (datetime.now() - start_time).total_seconds()
            self._log_tool_execution(tool_call, result, execution_time)
            
            return result
            
        except Exception as e:
            execution_time = (datetime.now() - start_time).total_seconds()
            error_str = str(e)
            
            # æ™ºèƒ½é”™è¯¯å¤„ç†ï¼šé’ˆå¯¹ä¸åŒé”™è¯¯ç±»å‹æä¾›è‡ªåŠ¨å›é€€ç­–ç•¥
            if self.error_handler.should_use_filter_fallback(tool_call.name, error_str):
                # è¿‡æ»¤å™¨é”™è¯¯ - å°è¯•è‡ªåŠ¨å›é€€ç­–ç•¥
                self.loggers['diagnosis'].warning(f"æ£€æµ‹åˆ°è¿‡æ»¤å™¨é”™è¯¯ï¼Œå°è¯•è‡ªåŠ¨å›é€€: {e}")
                
                fallback_result = self.error_handler.handle_filter_error_fallback(
                    tool_call.name, tool_call.parameters, e, self.tools
                )
                if fallback_result:
                    execution_time = (datetime.now() - start_time).total_seconds()
                    self._log_tool_execution(tool_call, fallback_result, execution_time)
                    return fallback_result
            
            # æ ‡å‡†é”™è¯¯å¤„ç†
            error_result = {
                "error": f"å·¥å…·æ‰§è¡Œå¤±è´¥: {error_str}",
                "tool": tool_call.name,
                "parameters": tool_call.parameters,
                "suggestion": self.error_handler.get_error_suggestion(tool_call.name, error_str)
            }
            
            self._log_tool_execution(tool_call, error_result, execution_time)
            self.error_handler.log_error_with_context(e, f"æ‰§è¡Œå·¥å…· {tool_call.name}", case_error_logger=case_error_logger)
            
            return error_result
    
    def _log_tool_execution(self, tool_call: ToolCall, result: Dict[str, Any], execution_time: float = 0):
        """è®°å½•å·¥å…·æ‰§è¡Œï¼Œå®‰å…¨å¤„ç†JSONåºåˆ—åŒ–"""
        self.loggers['tool'].info(f"æ‰§è¡Œå·¥å…·: {tool_call.name}")
        
        # å®‰å…¨çš„å‚æ•°åºåˆ—åŒ–
        try:
            safe_params = self._json_serialize_safe(tool_call.parameters)
            self.loggers['tool'].info(f"å‚æ•°: {json.dumps(safe_params, ensure_ascii=False, indent=2)}")
        except Exception as e:
            self.loggers['tool'].info(f"å‚æ•°: {str(tool_call.parameters)} (JSONåºåˆ—åŒ–å¤±è´¥: {e})")
        
        if "error" in result:
            self.loggers['tool'].error(f"å·¥å…·æ‰§è¡Œå¤±è´¥: {result['error']}")
        else:
            self.loggers['tool'].info(f"å·¥å…·æ‰§è¡ŒæˆåŠŸ")
            if "data" in result:
                self.loggers['tool'].info(f"æ•°æ®æ¡æ•°: {len(result['data'])}")
                self.loggers['tool'].info(f"æ•°æ®å½¢çŠ¶: {result.get('shape', 'N/A')}")
        
        if execution_time > 0:
            self.loggers['tool'].info(f"æ‰§è¡Œæ—¶é—´: {execution_time:.2f}ç§’")
        
        self.loggers['tool'].info("-" * 40)
    
    def _json_serialize_safe(self, obj: Any) -> Any:
        """
        å®‰å…¨çš„JSONåºåˆ—åŒ–ï¼Œå¤„ç†numpyæ•°ç»„ç­‰ç‰¹æ®Šç±»å‹
        
        Args:
            obj: è¦åºåˆ—åŒ–çš„å¯¹è±¡
            
        Returns:
            å¯åºåˆ—åŒ–çš„å¯¹è±¡
        """
        import numpy as np
        
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.bool_):
            return bool(obj)
        elif isinstance(obj, dict):
            return {key: self._json_serialize_safe(value) for key, value in obj.items()}
        elif isinstance(obj, list):
            return [self._json_serialize_safe(item) for item in obj]
        elif isinstance(obj, tuple):
            return [self._json_serialize_safe(item) for item in obj]
        else:
            return obj
    
    def format_tool_result(self, tool_call: ToolCall, result: Dict[str, Any]) -> str:
        """
        æ ¼å¼åŒ–å·¥å…·æ‰§è¡Œç»“æœä¸ºæ–‡æœ¬ï¼Œæ™ºèƒ½å‹ç¼©å¤§å‹ç»“æœ
        
        Args:
            tool_call: å·¥å…·è°ƒç”¨å¯¹è±¡
            result: å·¥å…·æ‰§è¡Œç»“æœ
            
        Returns:
            æ ¼å¼åŒ–çš„ç»“æœæ–‡æœ¬
        """
        formatted_result = f"=== Tool Execution Result: {tool_call.name} ===\n"
        
        # æ ¼å¼åŒ–ç»“æœ
        if "error" in result:
            formatted_result += f"âŒ Error: {result['error']}\n"
            if "suggestion" in result:
                formatted_result += f"ğŸ’¡ Suggestion: {result['suggestion']}\n"
        else:
            # æˆåŠŸæ‰§è¡Œ
            if tool_call.name == "attempt_completion":
                # åªæœ‰attempt_completionéœ€è¦JSONæ ¼å¼å¤„ç†
                formatted_result += f"âœ… {result.get('message', 'Task completed')}\n"
                if "result" in result:
                    formatted_result += f"Result: {json.dumps(result['result'], ensure_ascii=False, indent=2)}\n"
            else:
                # å…¶ä»–å·¥å…·éœ€è¦æ™ºèƒ½å‹ç¼©ç»“æœ
                formatted_result += f"âœ… Tool execution successful\n"
                
                # æ™ºèƒ½æ ¼å¼åŒ–å…³é”®ä¿¡æ¯
                if "data_too_large" in result:
                    formatted_result += f"âš ï¸ Data too large: {result.get('error', '')}\n"
                    formatted_result += f"Suggestion: {result.get('optimization_tips', [])[:2]}\n"
                elif "data" in result:
                    # æœ‰å®é™…æ•°æ®ï¼Œæ˜¾ç¤ºå…³é”®ä¿¡æ¯
                    data_info = f"æ•°æ®å½¢çŠ¶: {result.get('shape', 'N/A')}\n"
                    data_info += f"ä¼°ç®—tokens: {result.get('estimated_tokens', 'N/A')}\n"
                    
                    # åªæ˜¾ç¤ºå‰å‡ æ¡æ•°æ®
                    data = result.get("data", [])
                    if data:
                        data_info += f"Data example (first 3 rows): {data[:3]}\n"
                    
                    formatted_result += data_info
                else:
                    # å…¶ä»–ç»“æœä¿¡æ¯ï¼Œè¿›è¡Œå‹ç¼©
                    result_str = str(result)
                    compressed_result = self._compress_tool_result(result_str)
                    formatted_result += f"Raw return result:\n{compressed_result}\n"
        
        formatted_result += "=" * 50 + "\n"
        return formatted_result
    
    def _compress_tool_result(self, result_text: str, max_tokens: int = None) -> str:
        """å‹ç¼©å·¥å…·æ‰§è¡Œç»“æœï¼Œä¿ç•™å…³é”®ä¿¡æ¯"""
        if max_tokens is None:
            max_tokens = self.config.max_token_limit
            
        estimated_tokens = len(result_text) // self.config.token_estimation_ratio
        
        if estimated_tokens <= max_tokens:
            return result_text
        
        # æå–å…³é”®ä¿¡æ¯
        lines = result_text.split('\n')
        compressed_lines = []
        
        # ä¿ç•™æ ‡é¢˜è¡Œå’Œé”™è¯¯ä¿¡æ¯
        for line in lines[:5]:  # å‰5è¡Œé€šå¸¸åŒ…å«é‡è¦ä¿¡æ¯
            compressed_lines.append(line)
        
        # æŸ¥æ‰¾å¹¶ä¿ç•™åŒ…å«å…³é”®è¯çš„è¡Œ
        key_indicators = ['error', 'é”™è¯¯', 'failed', 'å¤±è´¥', 'success', 'æˆåŠŸ', 'shape', 'token', 'data']
        for line in lines[5:]:
            if any(indicator in line.lower() for indicator in key_indicators):
                compressed_lines.append(line)
        
        # æ·»åŠ å‹ç¼©æç¤º
        newline = '\n'
        compressed_lines.append(f"... [Result compressed, original length {estimated_tokens} tokens, compressed length {len(newline.join(compressed_lines))//self.config.token_estimation_ratio} tokens]")
        
        return '\n'.join(compressed_lines) 