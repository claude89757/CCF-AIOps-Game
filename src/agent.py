#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
@author: claude89757
@date: 2025-06-28
@description: CCF AIOpsæŒ‘æˆ˜èµ› Reactæ¨¡å¼æ•…éšœè¯Šæ–­æ™ºèƒ½ä½“
"""

import re
import json
import xml.etree.ElementTree as ET
from typing import Dict, Any, List, Callable, Optional, Union
from dataclasses import dataclass
from datetime import datetime
import os
import logging
import sys
from pathlib import Path

from src.model import ModelClient
from src.prompt import SYSTEM_PROMPT
from src.tools import preview_parquet_in_pd, get_data_from_parquet


@dataclass
class ToolCall:
    """å·¥å…·è°ƒç”¨æ•°æ®ç»“æ„"""
    name: str
    parameters: Dict[str, Any]


@dataclass
class AgentStep:
    """Agentæ‰§è¡Œæ­¥éª¤"""
    step_num: int
    action: str
    observation: str
    reasoning: Optional[str] = None


class LoggerSetup:
    """æ—¥å¿—ç³»ç»Ÿé…ç½®ç±»"""
    
    def __init__(self, base_dir: str = "src/logs"):
        self.base_dir = Path(base_dir)
        self.setup_directories()
        self.loggers = {}
        self.setup_loggers()
    
    def setup_directories(self):
        """åˆ›å»ºæ—¥å¿—ç›®å½•ç»“æ„"""
        directories = [
            self.base_dir / "diagnosis",    # è¯Šæ–­è¿‡ç¨‹æ—¥å¿—
            self.base_dir / "errors",       # é”™è¯¯æ—¥å¿—
            self.base_dir / "interactions", # æ™ºèƒ½ä½“äº¤äº’æ—¥å¿—
            self.base_dir / "tools",        # å·¥å…·æ‰§è¡Œæ—¥å¿—
            self.base_dir / "summary"       # æ€»ç»“æ—¥å¿—
        ]
        
        for directory in directories:
            directory.mkdir(parents=True, exist_ok=True)
    
    def setup_loggers(self):
        """è®¾ç½®ä¸åŒç±»å‹çš„æ—¥å¿—è®°å½•å™¨"""
        # è·å–å½“å‰æ—¶é—´ç”¨äºæ–‡ä»¶å‘½å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ä¸»è¯Šæ–­æ—¥å¿—
        self.loggers['diagnosis'] = self._create_logger(
            'diagnosis',
            self.base_dir / "diagnosis" / f"diagnosis_{timestamp}.log",
            level=logging.INFO
        )
        
        # é”™è¯¯æ—¥å¿—
        self.loggers['error'] = self._create_logger(
            'error',
            self.base_dir / "errors" / f"errors_{timestamp}.log",
            level=logging.ERROR
        )
        
        # äº¤äº’æ—¥å¿—
        self.loggers['interaction'] = self._create_logger(
            'interaction',
            self.base_dir / "interactions" / f"interactions_{timestamp}.log",
            level=logging.DEBUG
        )
        
        # å·¥å…·æ—¥å¿—
        self.loggers['tool'] = self._create_logger(
            'tool',
            self.base_dir / "tools" / f"tools_{timestamp}.log",
            level=logging.INFO
        )
        
        # æ€»ç»“æ—¥å¿—
        self.loggers['summary'] = self._create_logger(
            'summary',
            self.base_dir / "summary" / f"summary_{timestamp}.log",
            level=logging.INFO
        )
    
    def _create_logger(self, name: str, log_file: Path, level=logging.INFO):
        """åˆ›å»ºå•ä¸ªæ—¥å¿—è®°å½•å™¨"""
        logger = logging.getLogger(name)
        logger.setLevel(level)
        
        # é¿å…é‡å¤æ·»åŠ handler
        if logger.handlers:
            return logger
            
        # æ–‡ä»¶å¤„ç†å™¨
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_handler.setLevel(level)
        
        # æ§åˆ¶å°å¤„ç†å™¨
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setLevel(logging.WARNING if name == 'error' else logging.CRITICAL)
        
        # æ ¼å¼å™¨
        formatter = logging.Formatter(
            '%(asctime)s | %(name)s | %(levelname)s | %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        
        file_handler.setFormatter(formatter)
        console_handler.setFormatter(formatter)
        
        logger.addHandler(file_handler)
        logger.addHandler(console_handler)
        
        return logger
    
    def create_case_error_logger(self, uuid: str):
        """ä¸ºç‰¹å®šæ¡ˆä¾‹åˆ›å»ºé”™è¯¯æ—¥å¿—è®°å½•å™¨"""
        case_error_file = self.base_dir / "errors" / f"case_{uuid}_error.log"
        return self._create_logger(f'case_error_{uuid}', case_error_file, level=logging.ERROR)


class AIOpsReactAgent:
    """CCF AIOpsæŒ‘æˆ˜èµ›ä¸“ç”¨Reactæ¨¡å¼æ•…éšœè¯Šæ–­æ™ºèƒ½ä½“"""
    
    def __init__(self, model_name: str = "deepseek-v3:671b", max_iterations: int = 15):
        """
        åˆå§‹åŒ–Agent
        
        Args:
            model_name: ä½¿ç”¨çš„æ¨¡å‹åç§°
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œé˜²æ­¢æ— é™å¾ªç¯
        """
        # åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
        self.logger_setup = LoggerSetup()
        self.loggers = self.logger_setup.loggers
        
        self.model_client = ModelClient()
        self.model_name = model_name
        self.max_iterations = max_iterations
        
        # æ³¨å†Œå·¥å…·å‡½æ•°
        self.tools = self._register_tools()
        
        # è®°å½•æ‰§è¡Œæ­¥éª¤
        self.steps: List[AgentStep] = []
        self.current_step = 0
        
        # æ¯”èµ›ä¸“ç”¨é…ç½®
        self.competition_mode = True
        
        # å½“å‰æ¡ˆä¾‹çš„é”™è¯¯æ—¥å¿—è®°å½•å™¨
        self.case_error_logger = None
        
        # è®°å½•åˆå§‹åŒ–
        self.loggers['summary'].info("=== CCF AIOpsæ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆ ===")
        self.loggers['summary'].info(f"æ¨¡å‹: {model_name}")
        self.loggers['summary'].info(f"æœ€å¤§è¿­ä»£æ¬¡æ•°: {max_iterations}")
        self.loggers['summary'].info(f"å¯ç”¨å·¥å…·: {list(self.tools.keys())}")
    
    def _register_tools(self) -> Dict[str, Callable]:
        """æ³¨å†Œå¯ç”¨çš„å·¥å…·å‡½æ•°"""
        return {
            "preview_parquet_in_pd": preview_parquet_in_pd,
            "get_data_from_parquet": get_data_from_parquet,
            "attempt_completion": self._handle_completion
        }
    
    def _log_diagnosis_start(self, uuid: str, description: str):
        """è®°å½•è¯Šæ–­å¼€å§‹"""
        self.loggers['diagnosis'].info("=" * 80)
        self.loggers['diagnosis'].info(f"å¼€å§‹è¯Šæ–­æ•…éšœæ¡ˆä¾‹: {uuid}")
        self.loggers['diagnosis'].info(f"æ•…éšœæè¿°: {description}")
        self.loggers['diagnosis'].info("=" * 80)
    
    def _log_diagnosis_step(self, step_num: int, action: str, observation: str, reasoning: str = ""):
        """è®°å½•è¯Šæ–­æ­¥éª¤"""
        self.loggers['diagnosis'].info(f"æ­¥éª¤ {step_num}:")
        self.loggers['diagnosis'].info(f"  è¡ŒåŠ¨: {action}")
        self.loggers['diagnosis'].info(f"  è§‚å¯Ÿ: {observation[:200]}{'...' if len(observation) > 200 else ''}")
        if reasoning:
            self.loggers['diagnosis'].info(f"  æ¨ç†: {reasoning[:200]}{'...' if len(reasoning) > 200 else ''}")
        self.loggers['diagnosis'].info("-" * 40)
    
    def _log_tool_execution(self, tool_call: ToolCall, result: Dict[str, Any], execution_time: float = 0):
        """è®°å½•å·¥å…·æ‰§è¡Œ"""
        self.loggers['tool'].info(f"æ‰§è¡Œå·¥å…·: {tool_call.name}")
        self.loggers['tool'].info(f"å‚æ•°: {json.dumps(tool_call.parameters, ensure_ascii=False, indent=2)}")
        
        if "error" in result:
            self.loggers['tool'].error(f"å·¥å…·æ‰§è¡Œå¤±è´¥: {result['error']}")
            # åŒæ—¶è®°å½•åˆ°é”™è¯¯æ—¥å¿—
            if self.case_error_logger:
                self.case_error_logger.error(f"å·¥å…·æ‰§è¡Œå¤±è´¥ - {tool_call.name}: {result['error']}")
        else:
            self.loggers['tool'].info(f"å·¥å…·æ‰§è¡ŒæˆåŠŸ")
            if "data" in result:
                self.loggers['tool'].info(f"æ•°æ®æ¡æ•°: {len(result['data'])}")
                self.loggers['tool'].info(f"æ•°æ®å½¢çŠ¶: {result.get('shape', 'N/A')}")
        
        if execution_time > 0:
            self.loggers['tool'].info(f"æ‰§è¡Œæ—¶é—´: {execution_time:.2f}ç§’")
        
        self.loggers['tool'].info("-" * 40)
    
    def _log_model_interaction(self, iteration: int, messages_count: int, response_length: int):
        """è®°å½•æ¨¡å‹äº¤äº’"""
        self.loggers['interaction'].info(f"ç¬¬ {iteration} è½®æ¨¡å‹äº¤äº’")
        self.loggers['interaction'].info(f"æ¶ˆæ¯æ•°é‡: {messages_count}")
        self.loggers['interaction'].info(f"å“åº”é•¿åº¦: {response_length} å­—ç¬¦")
    
    def _log_error(self, error: Exception, context: str = "", uuid: str = ""):
        """è®°å½•é”™è¯¯ä¿¡æ¯"""
        import traceback
        
        error_msg = f"é”™è¯¯ä¸Šä¸‹æ–‡: {context}\né”™è¯¯ä¿¡æ¯: {str(error)}\nå †æ ˆè·Ÿè¸ª:\n{traceback.format_exc()}"
        
        self.loggers['error'].error(error_msg)
        
        # å¦‚æœæœ‰æ¡ˆä¾‹ç‰¹å®šçš„é”™è¯¯æ—¥å¿—è®°å½•å™¨ï¼Œä¹Ÿè®°å½•åˆ°é‚£é‡Œ
        if self.case_error_logger:
            self.case_error_logger.error(f"æ¡ˆä¾‹ {uuid} é”™è¯¯: {error_msg}")
    
    def _discover_relevant_files(self, description: str, debug: bool = False) -> str:
        """
        ä»æ•…éšœæè¿°ä¸­æå–æ—¶é—´çª—å£å¹¶å‘ç°ç›¸å…³æ–‡ä»¶
        
        Args:
            description: æ•…éšœæè¿°
            debug: æ˜¯å¦æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
            
        Returns:
            åŒ…å«æ–‡ä»¶ä¿¡æ¯çš„å­—ç¬¦ä¸²
        """
        import re
        import glob
        from datetime import datetime
        
        try:
            self.loggers['diagnosis'].info("å¼€å§‹å‘ç°ç›¸å…³æ–‡ä»¶...")
            
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ—¶é—´ä¿¡æ¯
            time_pattern = r'(\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}Z)'
            times = re.findall(time_pattern, description)
            
            if len(times) >= 2:
                start_time = times[0]
                end_time = times[1]
                
                self.loggers['diagnosis'].info(f"æå–åˆ°æ—¶é—´çª—å£: {start_time} to {end_time}")
                
                # è§£ææ—¶é—´å¹¶æå–æ—¥æœŸ
                start_dt = datetime.fromisoformat(start_time.replace('Z', '+00:00'))
                end_dt = datetime.fromisoformat(end_time.replace('Z', '+00:00'))
                start_date = start_dt.strftime('%Y-%m-%d')
                end_date = end_dt.strftime('%Y-%m-%d')
                
                # å‘ç°ç›¸å…³æ–‡ä»¶
                log_files = []
                metric_files = []
                trace_files = []
                
                # æ£€æŸ¥ç›®æ ‡æ—¥æœŸæ•°æ®æ˜¯å¦å­˜åœ¨
                data_dir = f"data/{start_date}"
                if not os.path.exists(data_dir):
                    # æŸ¥æ‰¾å¯ç”¨çš„æ—¥æœŸ
                    available_dates = []
                    for date_dir in glob.glob("data/2025-*"):
                        if os.path.isdir(date_dir):
                            date_name = os.path.basename(date_dir)
                            available_dates.append(date_name)
                    
                    self.loggers['diagnosis'].warning(f"æ—¥æœŸ {start_date} æ— æ•°æ®ï¼Œå¯ç”¨æ—¥æœŸ: {available_dates}")
                    
                    if available_dates:
                        available_dates = sorted(available_dates)
                        return f"âš ï¸ æ—¥æœŸ {start_date} æ— æ•°æ®ã€‚å¯ç”¨æ—¥æœŸ: {', '.join(available_dates)}ã€‚å»ºè®®ä½¿ç”¨æœ€æ¥è¿‘çš„æ—¥æœŸæ•°æ®è¿›è¡Œåˆ†æã€‚"
                    else:
                        return "âš ï¸ æœªæ‰¾åˆ°ä»»ä½•ç›‘æ§æ•°æ®ã€‚"
                
                # å‘ç°æ—¥å¿—æ–‡ä»¶
                log_pattern = f"{data_dir}/log-parquet/*.parquet"
                log_files = sorted(glob.glob(log_pattern))
                
                # å‘ç°è°ƒç”¨é“¾æ–‡ä»¶
                trace_pattern = f"{data_dir}/trace-parquet/*.parquet"
                trace_files = sorted(glob.glob(trace_pattern))
                
                # å‘ç°æŒ‡æ ‡æ–‡ä»¶ï¼ˆæ›´å¤æ‚çš„ç»“æ„ï¼‰
                apm_patterns = [
                    f"{data_dir}/metric-parquet/apm/*.parquet",
                    f"{data_dir}/metric-parquet/apm/*/*.parquet"
                ]
                for pattern in apm_patterns:
                    metric_files.extend(glob.glob(pattern))
                
                infra_patterns = [
                    f"{data_dir}/metric-parquet/infra/*.parquet",
                    f"{data_dir}/metric-parquet/infra/*/*.parquet"
                ]
                for pattern in infra_patterns:
                    metric_files.extend(glob.glob(pattern))
                
                other_pattern = f"{data_dir}/metric-parquet/other/*.parquet"
                metric_files.extend(glob.glob(other_pattern))
                
                metric_files = sorted(metric_files)
                
                self.loggers['diagnosis'].info(f"å‘ç°æ–‡ä»¶: {len(log_files)} æ—¥å¿—, {len(metric_files)} æŒ‡æ ‡, {len(trace_files)} è°ƒç”¨é“¾")
                
                # æ ¼å¼åŒ–æ–‡ä»¶ä¿¡æ¯
                file_info_parts = [
                    "## å¯ç”¨ç›‘æ§æ•°æ®æ–‡ä»¶",
                    f"æ—¶é—´çª—å£: {start_time} to {end_time}",
                    f"ç›¸å…³æ—¥æœŸ: {start_date}",
                    f"æ–‡ä»¶ç»Ÿè®¡: {len(log_files)} ä¸ªæ—¥å¿—æ–‡ä»¶, {len(metric_files)} ä¸ªæŒ‡æ ‡æ–‡ä»¶, {len(trace_files)} ä¸ªè°ƒç”¨é“¾æ–‡ä»¶"
                ]
                
                if log_files:
                    file_info_parts.append("\n### æ—¥å¿—æ–‡ä»¶:")
                    for log_file in log_files[:5]:  # æœ€å¤šæ˜¾ç¤º5ä¸ª
                        file_info_parts.append(f"- {log_file}")
                    if len(log_files) > 5:
                        file_info_parts.append(f"- ... ç­‰å…±{len(log_files)}ä¸ªæ—¥å¿—æ–‡ä»¶")
                
                if trace_files:
                    file_info_parts.append("\n### è°ƒç”¨é“¾æ–‡ä»¶:")
                    for trace_file in trace_files[:5]:  # æœ€å¤šæ˜¾ç¤º5ä¸ª
                        file_info_parts.append(f"- {trace_file}")
                    if len(trace_files) > 5:
                        file_info_parts.append(f"- ... ç­‰å…±{len(trace_files)}ä¸ªè°ƒç”¨é“¾æ–‡ä»¶")
                
                if metric_files:
                    file_info_parts.append("\n### æŒ‡æ ‡æ–‡ä»¶:")
                    for metric_file in metric_files[:8]:  # æœ€å¤šæ˜¾ç¤º8ä¸ª
                        file_info_parts.append(f"- {metric_file}")
                    if len(metric_files) > 8:
                        file_info_parts.append(f"- ... ç­‰å…±{len(metric_files)}ä¸ªæŒ‡æ ‡æ–‡ä»¶")
                
                file_info_parts.append("\nğŸ’¡ æç¤º: ä½¿ç”¨preview_parquet_in_pdå·¥å…·å…ˆé¢„è§ˆæ–‡ä»¶ç»“æ„ï¼Œå†ç”¨get_data_from_parquetè·å–å…·ä½“æ•°æ®ã€‚")
                
                return "\n".join(file_info_parts)
                
            else:
                # å¦‚æœæ— æ³•æå–æ—¶é—´ï¼Œå°è¯•æå–æ—¥æœŸ
                date_pattern = r'(\d{4}-\d{2}-\d{2})'
                dates = re.findall(date_pattern, description)
                
                if dates:
                    target_date = dates[0]
                    self.loggers['diagnosis'].info(f"æå–åˆ°æ—¥æœŸ: {target_date}")
                    
                    # æ£€æŸ¥è¯¥æ—¥æœŸçš„æ•°æ®æ˜¯å¦å­˜åœ¨
                    data_dir = f"data/{target_date}"
                    if not os.path.exists(data_dir):
                        # æŸ¥æ‰¾å¯ç”¨çš„æ—¥æœŸ
                        available_dates = []
                        for date_dir in glob.glob("data/2025-*"):
                            if os.path.isdir(date_dir):
                                date_name = os.path.basename(date_dir)
                                available_dates.append(date_name)
                        
                        if available_dates:
                            available_dates = sorted(available_dates)
                            return f"âš ï¸ æ—¥æœŸ {target_date} æ— æ•°æ®ã€‚å¯ç”¨æ—¥æœŸ: {', '.join(available_dates)}"
                        else:
                            return "âš ï¸ æœªæ‰¾åˆ°ä»»ä½•ç›‘æ§æ•°æ®ã€‚"
                    
                    return f"## å¯ç”¨ç›‘æ§æ•°æ®æ–‡ä»¶\nç›®æ ‡æ—¥æœŸ: {target_date}\nğŸ’¡ æç¤º: ä½¿ç”¨preview_parquet_in_pdå·¥å…·æ¢ç´¢å…·ä½“æ–‡ä»¶ã€‚"
        
        except Exception as e:
            self.loggers['diagnosis'].error(f"æ–‡ä»¶å‘ç°å¤±è´¥: {e}")
            return f"âš ï¸ æ— æ³•è‡ªåŠ¨å‘ç°æ–‡ä»¶: {str(e)}ã€‚è¯·æ‰‹åŠ¨ä½¿ç”¨preview_parquet_in_pdå·¥å…·æ¢ç´¢æ•°æ®ç»“æ„ã€‚"
        
        return "âš ï¸ æ— æ³•ä»æè¿°ä¸­æå–æ—¶é—´ä¿¡æ¯ã€‚è¯·æ‰‹åŠ¨ä½¿ç”¨preview_parquet_in_pdå·¥å…·æ¢ç´¢æ•°æ®ç»“æ„ã€‚"
    
    def _handle_completion(self, result: str) -> Dict[str, Any]:
        """å¤„ç†å®Œæˆä»»åŠ¡çš„å·¥å…·è°ƒç”¨"""
        try:
            self.loggers['diagnosis'].info("å°è¯•å®Œæˆä»»åŠ¡ï¼Œè§£æç»“æœ...")
            
            # å°è¯•è§£æJSONç»“æœ
            result_data = json.loads(result)
            
            # éªŒè¯å¿…éœ€å­—æ®µ
            required_fields = ["uuid", "component", "reason", "time", "reasoning_trace"]
            for field in required_fields:
                if field not in result_data:
                    error_msg = f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}"
                    self.loggers['diagnosis'].error(error_msg)
                    return {
                        "status": "error",
                        "error": error_msg,
                        "raw_result": result
                    }
            
            # éªŒè¯reasoning_traceæ ¼å¼
            if not isinstance(result_data["reasoning_trace"], list):
                error_msg = "reasoning_traceå¿…é¡»æ˜¯æ•°ç»„"
                self.loggers['diagnosis'].error(error_msg)
                return {
                    "status": "error",
                    "error": error_msg,
                    "raw_result": result
                }
            
            for i, step in enumerate(result_data["reasoning_trace"]):
                if not isinstance(step, dict) or "step" not in step or "action" not in step or "observation" not in step:
                    error_msg = f"reasoning_traceç¬¬{i+1}æ­¥æ ¼å¼é”™è¯¯ï¼Œéœ€è¦åŒ…å«stepã€actionã€observationå­—æ®µ"
                    self.loggers['diagnosis'].error(error_msg)
                    return {
                        "status": "error",
                        "error": error_msg,
                        "raw_result": result
                    }
            
            self.loggers['diagnosis'].info("ä»»åŠ¡å®Œæˆï¼Œç»“æœæ ¼å¼éªŒè¯é€šè¿‡")
            return {
                "status": "completed",
                "result": result_data,
                "message": "æ•…éšœè¯Šæ–­å®Œæˆï¼Œç»“æœæ ¼å¼éªŒè¯é€šè¿‡"
            }
            
        except json.JSONDecodeError as e:
            error_msg = f"JSONè§£æå¤±è´¥: {str(e)}"
            self.loggers['diagnosis'].error(error_msg)
            return {
                "status": "error",
                "error": error_msg,
                "raw_result": result
            }
    
    def parse_xml_tool_calls(self, text: str) -> List[ToolCall]:
        """
        è§£ææ–‡æœ¬ä¸­çš„XMLæ ¼å¼å·¥å…·è°ƒç”¨
        
        Args:
            text: åŒ…å«XMLå·¥å…·è°ƒç”¨çš„æ–‡æœ¬
            
        Returns:
            è§£æå‡ºçš„å·¥å…·è°ƒç”¨åˆ—è¡¨
        """
        tool_calls = []
        
        # æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„å·¥å…·è°ƒç”¨
        for tool_name in self.tools.keys():
            # æ„å»ºæ­£åˆ™è¡¨è¾¾å¼åŒ¹é…å¯¹åº”çš„XMLæ ‡ç­¾
            pattern = f'<{tool_name}>(.*?)</{tool_name}>'
            matches = re.findall(pattern, text, re.DOTALL)
            
            for match in matches:
                try:
                    # è§£æå‚æ•°
                    parameters = self._parse_tool_parameters(match.strip())
                    tool_calls.append(ToolCall(name=tool_name, parameters=parameters))
                    self.loggers['interaction'].debug(f"è§£æåˆ°å·¥å…·è°ƒç”¨: {tool_name}")
                except Exception as e:
                    self.loggers['interaction'].error(f"è§£æå·¥å…·è°ƒç”¨ {tool_name} æ—¶å‡ºé”™: {e}")
                    continue
        
        return tool_calls
    
    def _parse_tool_parameters(self, xml_content: str) -> Dict[str, Any]:
        """
        è§£æå·¥å…·å‚æ•°çš„XMLå†…å®¹
        
        Args:
            xml_content: XMLå‚æ•°å†…å®¹
            
        Returns:
            è§£æå‡ºçš„å‚æ•°å­—å…¸
        """
        parameters = {}
        
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…å‚æ•°æ ‡ç­¾
        param_pattern = r'<(\w+)>(.*?)</\1>'
        matches = re.findall(param_pattern, xml_content, re.DOTALL)
        
        for param_name, param_value in matches:
            param_value = param_value.strip()
            
            # å°è¯•è§£æç‰¹æ®Šç±»å‹çš„å‚æ•°
            if param_name == 'pd_read_kwargs':
                try:
                    # å°è¯•è§£æä¸ºå­—å…¸
                    parameters[param_name] = eval(param_value) if param_value else {}
                except:
                    parameters[param_name] = {}
            else:
                parameters[param_name] = param_value
        
        return parameters
    
    def execute_tool(self, tool_call: ToolCall) -> Dict[str, Any]:
        """
        æ‰§è¡Œå·¥å…·è°ƒç”¨
        
        Args:
            tool_call: å·¥å…·è°ƒç”¨å¯¹è±¡
            
        Returns:
            å·¥å…·æ‰§è¡Œç»“æœ
        """
        start_time = datetime.now()
        
        if tool_call.name not in self.tools:
            error_result = {
                "error": f"æœªçŸ¥å·¥å…·: {tool_call.name}",
                "available_tools": list(self.tools.keys())
            }
            self._log_tool_execution(tool_call, error_result)
            return error_result
        
        try:
            tool_func = self.tools[tool_call.name]
            result = tool_func(**tool_call.parameters)
            
            execution_time = (datetime.now() - start_time).total_seconds()
            self._log_tool_execution(tool_call, result, execution_time)
            
            return result
        except Exception as e:
            execution_time = (datetime.now() - start_time).total_seconds()
            error_result = {
                "error": f"å·¥å…·æ‰§è¡Œå¤±è´¥: {str(e)}",
                "tool": tool_call.name,
                "parameters": tool_call.parameters
            }
            
            self._log_tool_execution(tool_call, error_result, execution_time)
            self._log_error(e, f"æ‰§è¡Œå·¥å…· {tool_call.name}")
            
            return error_result
    
    def format_tool_result(self, tool_call: ToolCall, result: Dict[str, Any]) -> str:
        """
        æ ¼å¼åŒ–å·¥å…·æ‰§è¡Œç»“æœä¸ºæ–‡æœ¬
        
        Args:
            tool_call: å·¥å…·è°ƒç”¨å¯¹è±¡
            result: å·¥å…·æ‰§è¡Œç»“æœ
            
        Returns:
            æ ¼å¼åŒ–çš„ç»“æœæ–‡æœ¬
        """
        formatted_result = f"=== å·¥å…·æ‰§è¡Œç»“æœ: {tool_call.name} ===\n"
        
        # æ ¼å¼åŒ–ç»“æœ
        if "error" in result:
            formatted_result += f"âŒ é”™è¯¯: {result['error']}\n"
            if "suggestion" in result:
                formatted_result += f"ğŸ’¡ å»ºè®®: {result['suggestion']}\n"
        else:
            # æˆåŠŸæ‰§è¡Œ
            if tool_call.name == "attempt_completion":
                formatted_result += f"âœ… {result.get('message', 'ä»»åŠ¡å®Œæˆ')}\n"
                if "result" in result:
                    formatted_result += f"ç»“æœ: {json.dumps(result['result'], ensure_ascii=False, indent=2)}\n"
            else:
                # æ•°æ®å·¥å…·çš„ç»“æœ
                if "data" in result:
                    data_count = len(result["data"])
                    formatted_result += f"âœ… æˆåŠŸè·å– {data_count} æ¡æ•°æ®\n"
                    formatted_result += f"å½¢çŠ¶: {result.get('shape', 'N/A')}\n"
                    formatted_result += f"åˆ—å: {result.get('columns', [])}\n"
                    formatted_result += f"ä¼°ç®—Tokenæ•°: {result.get('estimated_tokens', 'N/A')}\n"
                    
                    # æ˜¾ç¤ºéƒ¨åˆ†æ•°æ®æ ·ä¾‹
                    if data_count > 0:
                        formatted_result += f"æ•°æ®æ ·ä¾‹ (å‰2æ¡):\n"
                        for i, record in enumerate(result["data"][:2]):
                            formatted_result += f"  {i+1}. {json.dumps(record, ensure_ascii=False)}\n"
                else:
                    # é¢„è§ˆç»“æœæˆ–å…¶ä»–ç»“æœ
                    for key, value in result.items():
                        if key not in ["data", "error"]:
                            formatted_result += f"{key}: {value}\n"
        
        formatted_result += "=" * 50 + "\n"
        return formatted_result
    
    def diagnose_single_case(self, case: Dict[str, str], debug: bool = False) -> Dict[str, Any]:
        """
        è¯Šæ–­å•ä¸ªæ•…éšœæ¡ˆä¾‹
        
        Args:
            case: æ•…éšœæ¡ˆä¾‹ï¼ŒåŒ…å«uuidå’ŒAnomaly Description
            debug: æ˜¯å¦æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
            
        Returns:
            è¯Šæ–­ç»“æœ
        """
        uuid = case["uuid"]
        description = case["Anomaly Description"]
        
        # åˆ›å»ºæ¡ˆä¾‹ç‰¹å®šçš„é”™è¯¯æ—¥å¿—è®°å½•å™¨
        self.case_error_logger = self.logger_setup.create_case_error_logger(uuid)
        
        # è®°å½•è¯Šæ–­å¼€å§‹
        self._log_diagnosis_start(uuid, description)
        
        print(f"\nğŸ” å¼€å§‹è¯Šæ–­æ•…éšœæ¡ˆä¾‹: {uuid}")
        print(f"æè¿°: {description}")
        print("=" * 80)
        
        # é‡ç½®æ­¥éª¤è®¡æ•°
        self.steps = []
        self.current_step = 0
        
        try:
            # ä»æ•…éšœæè¿°ä¸­æå–æ—¶é—´çª—å£å¹¶å‘ç°ç›¸å…³æ–‡ä»¶
            file_info = self._discover_relevant_files(description, debug)
            
            # æ„å»ºé’ˆå¯¹æ¯”èµ›çš„ä¸“ç”¨ä»»åŠ¡æç¤º
            task_prompt = f"""
è¯·åˆ†æä»¥ä¸‹æ•…éšœæ¡ˆä¾‹å¹¶è¿›è¡Œæ ¹å› å®šä½ï¼š

æ•…éšœæ¡ˆä¾‹UUID: {uuid}
æ•…éšœæè¿°: {description}

{file_info}

ä½ éœ€è¦ï¼š
1. åˆ†ææ•…éšœå‘ç”Ÿçš„æ—¶é—´çª—å£
2. ç³»ç»Ÿæ€§åˆ†æç›¸å…³ç›‘æ§æ•°æ®ï¼ˆlogsã€metricsã€tracesï¼‰
3. è¯†åˆ«æ ¹å› ç»„ä»¶ï¼ˆcomponentï¼‰
4. ç¡®å®šæ•…éšœåŸå› ï¼ˆreasonï¼‰
5. æä¾›å®Œæ•´çš„æ¨ç†è½¨è¿¹ï¼ˆreasoning_traceï¼‰

è¦æ±‚ï¼š
- æ¯ä¸ªæ¨ç†æ­¥éª¤å¿…é¡»åŒ…å«å…·ä½“çš„actionå’Œobservation
- observationå­—æ®µæ§åˆ¶åœ¨100å­—ä»¥å†…ï¼Œçªå‡ºå…³é”®ä¿¡æ¯
- å¿…é¡»æ”¶é›†å¤šç»´åº¦è¯æ®ï¼ˆæŒ‡æ ‡å¼‚å¸¸ã€æ—¥å¿—é”™è¯¯ã€è°ƒç”¨é“¾å¼‚å¸¸ï¼‰
- æ¨ç†æ­¥éª¤è¦ç´§å‡‘é«˜æ•ˆï¼Œé¿å…å†—ä½™
- æœ€ç»ˆä½¿ç”¨attempt_completionæäº¤ç»“æœ

è¯·å¼€å§‹åˆ†æã€‚
            """
            
            # æ„å»ºåˆå§‹æ¶ˆæ¯
            messages = [
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": task_prompt}
            ]
            
            iteration = 0
            final_result = None
            
            while iteration < self.max_iterations:
                iteration += 1
                self.current_step += 1
                
                self.loggers['diagnosis'].info(f"ç¬¬ {iteration} è½®æ¨ç†å¼€å§‹...")
                
                if debug:
                    print(f"\nğŸ”„ ç¬¬ {iteration} è½®æ¨ç†...")
                
                try:
                    # è®°å½•æ¨¡å‹äº¤äº’
                    self._log_model_interaction(iteration, len(messages), 0)
                    
                    # è·å–æ¨¡å‹å“åº”ï¼Œè®¾ç½®temperature=0ç¡®ä¿ç¨³å®šæ€§
                    response = self.model_client.chat(
                        messages=messages,
                        model=self.model_name,
                        temperature=0.0,  # æ¯”èµ›è¦æ±‚ç¨³å®šè¾“å‡º
                        debug=debug
                    )
                    
                    # æ›´æ–°äº¤äº’æ—¥å¿—
                    self._log_model_interaction(iteration, len(messages), len(response))
                    
                    if debug:
                        print(f"ğŸ“ æ¨¡å‹å“åº”:\n{response[:200]}...\n")
                    
                    # è§£æå·¥å…·è°ƒç”¨
                    tool_calls = self.parse_xml_tool_calls(response)
                    
                    if not tool_calls:
                        self.loggers['diagnosis'].warning("æœªæ£€æµ‹åˆ°å·¥å…·è°ƒç”¨ï¼Œä»»åŠ¡å¯èƒ½å·²å®Œæˆæˆ–å­˜åœ¨é—®é¢˜")
                        if debug:
                            print("âŒ æœªæ£€æµ‹åˆ°å·¥å…·è°ƒç”¨ï¼Œä»»åŠ¡å¯èƒ½å·²å®Œæˆæˆ–å­˜åœ¨é—®é¢˜")
                        break
                    
                    # æ‰§è¡Œå·¥å…·è°ƒç”¨
                    tool_results = []
                    for tool_call in tool_calls:
                        if debug:
                            print(f"ğŸ”§ æ‰§è¡Œå·¥å…·: {tool_call.name}")
                        
                        result = self.execute_tool(tool_call)
                        tool_results.append((tool_call, result))
                        
                        # è®°å½•æ‰§è¡Œæ­¥éª¤
                        step = AgentStep(
                            step_num=self.current_step,
                            action=f"{tool_call.name}({json.dumps(tool_call.parameters, ensure_ascii=False)})",
                            observation=str(result)[:100] + "..." if len(str(result)) > 100 else str(result),
                            reasoning=response[:100] + "..." if len(response) > 100 else response
                        )
                        self.steps.append(step)
                        self._log_diagnosis_step(self.current_step, step.action, step.observation, step.reasoning)
                        
                        # æ£€æŸ¥æ˜¯å¦å®Œæˆä»»åŠ¡
                        if tool_call.name == "attempt_completion" and "status" in result:
                            if result["status"] == "completed":
                                final_result = result.get("result")
                                self.loggers['diagnosis'].info("æ•…éšœè¯Šæ–­æˆåŠŸå®Œæˆ!")
                                if debug:
                                    print("âœ… æ•…éšœè¯Šæ–­å®Œæˆ!")
                                return {
                                    "status": "completed",
                                    "result": final_result,
                                    "steps": self.steps,
                                    "iterations": iteration
                                }
                            else:
                                error_msg = f"ä»»åŠ¡å®Œæˆè°ƒç”¨å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"
                                self.loggers['diagnosis'].error(error_msg)
                                if self.case_error_logger:
                                    self.case_error_logger.error(error_msg)
                                if debug:
                                    print(f"âš ï¸ {error_msg}")
                    
                    # å°†å·¥å…·ç»“æœæ·»åŠ åˆ°å¯¹è¯å†å²
                    tool_results_text = "\n".join([
                        self.format_tool_result(tool_call, result) 
                        for tool_call, result in tool_results
                    ])
                    
                    messages.append({"role": "assistant", "content": response})
                    messages.append({"role": "user", "content": f"å·¥å…·æ‰§è¡Œç»“æœ:\n{tool_results_text}\nç»§ç»­åˆ†æã€‚"})
                    
                except Exception as e:
                    error_msg = f"ç¬¬ {iteration} è½®æ‰§è¡Œå‡ºé”™: {e}"
                    self.loggers['diagnosis'].error(error_msg)
                    self._log_error(e, f"ç¬¬ {iteration} è½®æ‰§è¡Œ", uuid)
                    print(f"âŒ {error_msg}")
                    if debug:
                        import traceback
                        traceback.print_exc()
                    break
            
            # è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°æˆ–å…¶ä»–åŸå› ç»“æŸ
            result_summary = {
                "status": "incomplete",
                "result": final_result,
                "steps": self.steps,
                "iterations": iteration,
                "reason": "è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°" if iteration >= self.max_iterations else "æ‰§è¡Œä¸­æ–­"
            }
            
            self.loggers['diagnosis'].warning(f"è¯Šæ–­æœªå®Œæˆ: {result_summary['reason']}")
            return result_summary
            
        except Exception as e:
            self._log_error(e, "è¯Šæ–­å•ä¸ªæ¡ˆä¾‹", uuid)
            return {
                "status": "error", 
                "error": str(e),
                "steps": self.steps,
                "iterations": 0
            }
    
    def process_input_json(self, input_file: str = "input.json", output_file: str = "answer.json", debug: bool = False) -> Dict[str, Any]:
        """
        å¤„ç†input.jsonæ–‡ä»¶ä¸­çš„æ‰€æœ‰æ•…éšœæ¡ˆä¾‹ï¼Œç”Ÿæˆanswer.json
        
        Args:
            input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            debug: æ˜¯å¦æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
            
        Returns:
            å¤„ç†ç»“æœç»Ÿè®¡
        """
        print(f"ğŸš€ å¼€å§‹å¤„ç† CCF AIOps æŒ‘æˆ˜èµ›æ•…éšœæ¡ˆä¾‹")
        print(f"è¾“å…¥æ–‡ä»¶: {input_file}")
        print(f"è¾“å‡ºæ–‡ä»¶: {output_file}")
        print("=" * 80)
        
        self.loggers['summary'].info("=" * 80)
        self.loggers['summary'].info("å¼€å§‹å¤„ç† CCF AIOps æŒ‘æˆ˜èµ›æ•…éšœæ¡ˆä¾‹")
        self.loggers['summary'].info(f"è¾“å…¥æ–‡ä»¶: {input_file}")
        self.loggers['summary'].info(f"è¾“å‡ºæ–‡ä»¶: {output_file}")
        self.loggers['summary'].info("=" * 80)
        
        # è¯»å–è¾“å…¥æ–‡ä»¶
        try:
            with open(input_file, 'r', encoding='utf-8') as f:
                cases = json.load(f)
        except Exception as e:
            error_msg = f"è¯»å–è¾“å…¥æ–‡ä»¶å¤±è´¥: {e}"
            print(f"âŒ {error_msg}")
            self.loggers['summary'].error(error_msg)
            self._log_error(e, "è¯»å–è¾“å…¥æ–‡ä»¶")
            return {"status": "error", "error": str(e)}
        
        print(f"ğŸ“Š å…±å‘ç° {len(cases)} ä¸ªæ•…éšœæ¡ˆä¾‹")
        self.loggers['summary'].info(f"å…±å‘ç° {len(cases)} ä¸ªæ•…éšœæ¡ˆä¾‹")
        
        # å¤„ç†æ‰€æœ‰æ¡ˆä¾‹
        results = []
        successful_count = 0
        failed_count = 0
        
        for i, case in enumerate(cases):
            try:
                print(f"\n{'='*80}")
                print(f"è¿›åº¦: {i+1}/{len(cases)} - {(i+1)/len(cases)*100:.1f}%")
                
                self.loggers['summary'].info(f"å¤„ç†æ¡ˆä¾‹ {i+1}/{len(cases)}: {case.get('uuid', 'unknown')}")
                
                # è¯Šæ–­å•ä¸ªæ¡ˆä¾‹
                diagnosis_result = self.diagnose_single_case(case, debug=debug)
                
                if diagnosis_result["status"] == "completed" and diagnosis_result["result"]:
                    results.append(diagnosis_result["result"])
                    successful_count += 1
                    success_msg = f"æ¡ˆä¾‹ {case['uuid']} è¯Šæ–­å®Œæˆ"
                    print(f"âœ… {success_msg}")
                    self.loggers['summary'].info(success_msg)
                else:
                    failed_count += 1
                    fail_msg = f"æ¡ˆä¾‹ {case['uuid']} è¯Šæ–­å¤±è´¥: {diagnosis_result.get('reason', 'æœªçŸ¥åŸå› ')}"
                    print(f"âŒ {fail_msg}")
                    self.loggers['summary'].error(fail_msg)
                    
                    # ä¸ºå¤±è´¥çš„æ¡ˆä¾‹ç”Ÿæˆä¸€ä¸ªåŸºæœ¬ç»“æœï¼Œé¿å…ä¸¢å¤±
                    fallback_result = {
                        "uuid": case["uuid"],
                        "component": "unknown",
                        "reason": "analysis_failed", 
                        "time": "2025-06-06 12:00:00",
                        "reasoning_trace": [
                            {
                                "step": 1,
                                "action": "DiagnosisAttempt",
                                "observation": "Automatic diagnosis failed, requires manual investigation"
                            }
                        ]
                    }
                    results.append(fallback_result)
                
            except Exception as e:
                error_msg = f"å¤„ç†æ¡ˆä¾‹ {case.get('uuid', 'unknown')} æ—¶å‡ºé”™: {e}"
                print(f"âŒ {error_msg}")
                self.loggers['summary'].error(error_msg)
                self._log_error(e, f"å¤„ç†æ¡ˆä¾‹ {case.get('uuid', 'unknown')}")
                failed_count += 1
                if debug:
                    import traceback
                    traceback.print_exc()
        
        # ä¿å­˜ç»“æœ
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            save_msg = f"ç»“æœå·²ä¿å­˜åˆ° {output_file}"
            print(f"\nâœ… {save_msg}")
            self.loggers['summary'].info(save_msg)
        except Exception as e:
            error_msg = f"ä¿å­˜ç»“æœå¤±è´¥: {e}"
            print(f"âŒ {error_msg}")
            self.loggers['summary'].error(error_msg)
            self._log_error(e, "ä¿å­˜ç»“æœ")
            return {"status": "error", "error": f"ä¿å­˜å¤±è´¥: {str(e)}"}
        
        # è¿”å›ç»Ÿè®¡ç»“æœ
        summary = {
            "status": "completed",
            "total_cases": len(cases),
            "successful_cases": successful_count,
            "failed_cases": failed_count,
            "success_rate": successful_count / len(cases) * 100,
            "output_file": output_file
        }
        
        print(f"\n{'='*80}")
        print(f"ğŸ“Š å¤„ç†å®Œæˆç»Ÿè®¡:")
        print(f"æ€»æ¡ˆä¾‹æ•°: {summary['total_cases']}")
        print(f"æˆåŠŸæ¡ˆä¾‹: {summary['successful_cases']}")
        print(f"å¤±è´¥æ¡ˆä¾‹: {summary['failed_cases']}")
        print(f"æˆåŠŸç‡: {summary['success_rate']:.1f}%")
        print(f"{'='*80}")
        
        # è®°å½•æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯
        self.loggers['summary'].info("=" * 80)
        self.loggers['summary'].info("å¤„ç†å®Œæˆç»Ÿè®¡:")
        self.loggers['summary'].info(f"æ€»æ¡ˆä¾‹æ•°: {summary['total_cases']}")
        self.loggers['summary'].info(f"æˆåŠŸæ¡ˆä¾‹: {summary['successful_cases']}")
        self.loggers['summary'].info(f"å¤±è´¥æ¡ˆä¾‹: {summary['failed_cases']}")
        self.loggers['summary'].info(f"æˆåŠŸç‡: {summary['success_rate']:.1f}%")
        self.loggers['summary'].info("=" * 80)
        
        return summary


def main():
    """ä¸»å‡½æ•° - æ¯”èµ›æ¨¡å¼"""
    # åˆ›å»ºæ™ºèƒ½ä½“
    agent = AIOpsReactAgent(model_name="deepseek-v3:671b", max_iterations=12)
    
    print("ğŸ† CCF AIOpsæŒ‘æˆ˜èµ›æ•…éšœè¯Šæ–­æ™ºèƒ½ä½“")
    print("=" * 80)
    
    # å¤„ç†æ‰€æœ‰æ•…éšœæ¡ˆä¾‹
    result = agent.process_input_json(
        input_file="input.json",
        output_file="answer.json", 
        debug=False
    )
    
    if result["status"] == "completed":
        print(f"\nğŸ‰ æ¯”èµ›æäº¤æ–‡ä»¶å·²ç”Ÿæˆ!")
        print(f"ğŸ“ æ–‡ä»¶ä½ç½®: {result['output_file']}")
        print(f"ğŸ“ˆ æˆåŠŸç‡: {result['success_rate']:.1f}%")
    else:
        print(f"\nâŒ å¤„ç†å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")


if __name__ == "__main__":
    main()
