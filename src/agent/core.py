#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
@author: claude89757
@date: 2025-06-29
@description: CCF AIOpsæŒ‘æˆ˜èµ› Reactæ¨¡å¼æ•…éšœè¯Šæ–­æ™ºèƒ½ä½“æ ¸å¿ƒé€»è¾‘
"""

import re
import json
import time
import xml.etree.ElementTree as ET
from typing import Dict, Any, List, Optional
from dataclasses import dataclass
from datetime import datetime

from ..config import AgentConfig
from ..log_system import LoggerSetup
from ..model import ModelClient
from ..prompt import SYSTEM_PROMPT

from .tool_executor import ToolCall, ToolExecutor
from .context_manager import ContextManager
from .error_handler import ErrorHandler
from .file_discovery import FileDiscovery


@dataclass
class AgentStep:
    """Agentæ‰§è¡Œæ­¥éª¤"""
    step_num: int
    action: str
    observation: str
    reasoning: Optional[str] = None


class AIOpsReactAgent:
    """CCF AIOpsæŒ‘æˆ˜èµ›ä¸“ç”¨Reactæ¨¡å¼æ•…éšœè¯Šæ–­æ™ºèƒ½ä½“"""
    
    # å·²ç”³è¯·æ”¯æŒçš„æ¨¡å‹é…ç½®ï¼ˆå§”æ‰˜ç»™é…ç½®ç±»ï¼‰
    MODEL_CONFIGS = AgentConfig().MODEL_CONFIGS
    
    def __init__(self, model_name: str = "deepseek-v3:671b", max_iterations: int = 15, max_model_retries: int = 3, 
                 max_context_length: Optional[int] = None, temperature: Optional[float] = None):
        """
        åˆå§‹åŒ–Agent
        
        Args:
            model_name: ä½¿ç”¨çš„æ¨¡å‹åç§°
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œé˜²æ­¢æ— é™å¾ªç¯
            max_model_retries: æ¨¡å‹è°ƒç”¨æœ€å¤§é‡è¯•æ¬¡æ•°
            max_context_length: æ¨¡å‹æ”¯æŒçš„æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦ï¼ˆtokensï¼‰ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨æ¨¡å‹çš„å»ºè®®é…ç½®
            temperature: æ¨¡å‹ç”Ÿæˆæ¸©åº¦ï¼Œ0.0ä¸ºç¡®å®šæ€§è¾“å‡ºï¼Œå€¼è¶Šé«˜éšæœºæ€§è¶Šå¼ºï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨æ¨¡å‹çš„å»ºè®®é…ç½®
        """
        # åˆå§‹åŒ–é…ç½®
        self.config = AgentConfig()
        self.config.max_iterations = max_iterations
        self.config.max_model_retries = max_model_retries
        
        # è‡ªåŠ¨é…ç½®æ¨¡å‹å‚æ•°
        model_config = self.config.get_model_config(model_name)
        
        self.model_client = ModelClient()
        self.model_name = model_name
        self.max_context_length = max_context_length if max_context_length is not None else model_config["max_context_length"]
        self.temperature = temperature if temperature is not None else model_config["temperature"]
        
        # åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
        self.logger_setup = LoggerSetup(self.config.log_base_dir)
        self.loggers = self.logger_setup.loggers
        
        # åˆå§‹åŒ–å„ä¸ªç»„ä»¶
        self.tool_executor = ToolExecutor(self.config, self.loggers)
        self.context_manager = ContextManager(self.config, self.loggers, self.max_context_length)
        self.error_handler = ErrorHandler(self.config)
        self.file_discovery = FileDiscovery(self.config, self.loggers)
        
        # è®°å½•æ‰§è¡Œæ­¥éª¤
        self.steps: List[AgentStep] = []
        self.current_step = 0
        
        # æ¯”èµ›ä¸“ç”¨é…ç½®
        self.competition_mode = True
        
        # å½“å‰æ¡ˆä¾‹çš„é”™è¯¯æ—¥å¿—è®°å½•å™¨
        self.case_error_logger = None
        
        # è®°å½•åˆå§‹åŒ–
        self._log_initialization()
    
    def _log_initialization(self):
        """è®°å½•åˆå§‹åŒ–ä¿¡æ¯"""
        self.loggers['summary'].info("=== CCF AIOpsæ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆ ===")
        self.loggers['summary'].info(f"æ¨¡å‹: {self.model_name}")
        
        # æ˜¾ç¤ºé…ç½®æ¥æº
        context_source = "auto-configured" if self.max_context_length == self.config.get_model_config(self.model_name)["max_context_length"] else "user-specified"
        temp_source = "auto-configured" if self.temperature == self.config.get_model_config(self.model_name)["temperature"] else "user-specified"
        
        self.loggers['summary'].info(f"æ¨¡å‹é…ç½®: æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦={self.max_context_length:,}tokens ({context_source}), æ¸©åº¦={self.temperature} ({temp_source})")
        self.loggers['summary'].info(f"æœ€å¤§è¿­ä»£æ¬¡æ•°: {self.config.max_iterations}")
        self.loggers['summary'].info(f"å¯ç”¨å·¥å…·: {list(self.tool_executor.tools.keys())}")
        self.loggers['summary'].info(f"æ¨¡å‹é‡è¯•æ¬¡æ•°: {self.config.max_model_retries}")
        self.loggers['summary'].info(f"ä¸Šä¸‹æ–‡ç®¡ç†: æœ€å¤§{self.context_manager.max_context_tokens}tokensï¼Œå‹ç¼©é˜ˆå€¼{self.context_manager.context_compress_threshold}tokensï¼Œå·¥å…·ç»“æœé™åˆ¶{self.context_manager.max_tool_result_tokens}tokens")
    
    @classmethod
    def get_supported_models(cls) -> Dict[str, Dict[str, Any]]:
        """è·å–æ”¯æŒçš„æ¨¡å‹é…ç½®ä¿¡æ¯"""
        return cls.MODEL_CONFIGS.copy()
    
    @classmethod 
    def print_supported_models(cls):
        """æ‰“å°æ”¯æŒçš„æ¨¡å‹é…ç½®"""
        print("Supported models and their recommended configurations:")
        print("=" * 60)
        for model, config in cls.MODEL_CONFIGS.items():
            print(f"Model: {model}")
            print(f"  Max Context Length: {config['max_context_length']:,} tokens")
            print(f"  Temperature: {config['temperature']}")
            print("-" * 40)
    
    def _log_diagnosis_start(self, uuid: str, description: str):
        """è®°å½•è¯Šæ–­å¼€å§‹"""
        self.loggers['diagnosis'].info("=" * 80)
        self.loggers['diagnosis'].info(f"å¼€å§‹è¯Šæ–­æ•…éšœæ¡ˆä¾‹: {uuid}")
        self.loggers['diagnosis'].info(f"æ•…éšœæè¿°: {description}")
        self.loggers['diagnosis'].info("=" * 80)
    
    def _log_diagnosis_step(self, step_num: int, action: str, observation: str, reasoning: str = ""):
        """è®°å½•è¯Šæ–­æ­¥éª¤ - å¢å¼ºç‰ˆæœ¬ï¼ŒåŒ…å«è¯¦ç»†å’Œç®€åŒ–ä¸¤ç§æ—¥å¿—"""
        # ç®€åŒ–ç‰ˆæœ¬ç”¨äºå¿«é€Ÿæµè§ˆ
        self.loggers['diagnosis'].info(f"æ­¥éª¤ {step_num}:")
        self.loggers['diagnosis'].info(f"  è¡ŒåŠ¨: {action}")
        self.loggers['diagnosis'].info(f"  è§‚å¯Ÿç®€è¦: {observation[:300]}{'...' if len(observation) > 300 else ''}")
        if reasoning:
            self.loggers['diagnosis'].info(f"  æ¨ç†ç®€è¦: {reasoning[:300]}{'...' if len(reasoning) > 300 else ''}")
        self.loggers['diagnosis'].info("-" * 40)
        
        # è¯¦ç»†ç‰ˆæœ¬è®°å½•åˆ°äº¤äº’æ—¥å¿— - å®Œæ•´ä¿¡æ¯
        self.loggers['interaction'].info(f"=== è¯Šæ–­æ­¥éª¤ {step_num} - è¯¦ç»†ä¿¡æ¯ ===")
        self.loggers['interaction'].info(f"è¡ŒåŠ¨: {action}")
        self.loggers['interaction'].info(f"è§‚å¯Ÿå®Œæ•´å†…å®¹ (é•¿åº¦: {len(observation)} å­—ç¬¦):")
        self.loggers['interaction'].info(f"{observation}")
        if reasoning:
            self.loggers['interaction'].info(f"æ¨ç†å®Œæ•´å†…å®¹ (é•¿åº¦: {len(reasoning)} å­—ç¬¦):")
            self.loggers['interaction'].info(f"{reasoning}")
        self.loggers['interaction'].info("=" * 60)
    
    def _log_model_interaction(self, iteration: int, messages_count: int, response_length: int, response_preview: str = ""):
        """è®°å½•æ¨¡å‹äº¤äº’ - å¢å¼ºç‰ˆæœ¬"""
        self.loggers['interaction'].info(f"ç¬¬ {iteration} è½®æ¨¡å‹äº¤äº’")
        self.loggers['interaction'].info(f"æ¶ˆæ¯æ•°é‡: {messages_count}")
        self.loggers['interaction'].info(f"å“åº”é•¿åº¦: {response_length} å­—ç¬¦")
        if response_preview:
            self.loggers['interaction'].info(f"å“åº”é¢„è§ˆ: {response_preview[:500]}{'...' if len(response_preview) > 500 else ''}")
            # å®Œæ•´å“åº”è®°å½•åˆ°è¯¦ç»†æ—¥å¿—
            self.loggers['interaction'].debug(f"å®Œæ•´å“åº”å†…å®¹:\n{response_preview}")
    
    def _log_llm_interaction(self, iteration: int, uuid: str, input_messages: List[Dict[str, Any]], 
                           output_response: str, duration: float = 0, model_name: str = ""):
        """è®°å½•å¤§æ¨¡å‹åŸå§‹äº¤äº’ä¿¡æ¯"""
        separator = "=" * 100
        
        interaction_data = {
            "interaction_id": f"{uuid}_{iteration}_{datetime.now().strftime('%H%M%S')}",
            "timestamp": datetime.now().isoformat(),
            "iteration": iteration,
            "case_uuid": uuid,
            "model": model_name,
            "duration_seconds": round(duration, 3),
            "input": {
                "messages_count": len(input_messages),
                "messages": input_messages,
                "total_input_length": sum(len(str(msg.get('content', ''))) for msg in input_messages)
            },
            "output": {
                "response": output_response,
                "response_length": len(output_response)
            }
        }
        
        # æ ¼å¼åŒ–JSONè¾“å‡ºï¼Œç¡®ä¿ä¸­æ–‡æ˜¾ç¤ºæ­£å¸¸
        formatted_json = json.dumps(interaction_data, ensure_ascii=False, indent=2)
        
        # è®°å½•åˆ°æ—¥å¿—
        self.loggers['llm_interactions'].info(f"\n{separator}")
        self.loggers['llm_interactions'].info(f"LLM INTERACTION #{iteration} - CASE: {uuid}")
        self.loggers['llm_interactions'].info(f"{separator}")
        self.loggers['llm_interactions'].info(formatted_json)
        self.loggers['llm_interactions'].info(f"{separator}\n")
    
    def parse_xml_tool_calls(self, text: str) -> List[ToolCall]:
        """
        è§£ææ–‡æœ¬ä¸­çš„XMLæ ¼å¼å·¥å…·è°ƒç”¨ï¼ŒåŒ…å«å‚æ•°éªŒè¯
        
        Args:
            text: åŒ…å«XMLå·¥å…·è°ƒç”¨çš„æ–‡æœ¬
            
        Returns:
            è§£æå‡ºçš„å·¥å…·è°ƒç”¨åˆ—è¡¨
        """
        tool_calls = []
        
        # æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„å·¥å…·è°ƒç”¨
        for tool_name in self.tool_executor.tools.keys():
            # æ„å»ºæ­£åˆ™è¡¨è¾¾å¼åŒ¹é…å¯¹åº”çš„XMLæ ‡ç­¾
            pattern = f'<{tool_name}>(.*?)</{tool_name}>'
            matches = re.findall(pattern, text, re.DOTALL)
            
            for match in matches:
                try:
                    # è§£æå‚æ•°
                    parameters = self._parse_tool_parameters(match.strip())
                    tool_calls.append(ToolCall(name=tool_name, parameters=parameters))
                    self.loggers['interaction'].debug(f"è§£æåˆ°å·¥å…·è°ƒç”¨: {tool_name}")
                except Exception as e:
                    self.loggers['interaction'].error(f"è§£æå·¥å…·è°ƒç”¨ {tool_name} æ—¶å‡ºé”™: {e}")
                    continue
        
        return tool_calls
    
    def _parse_tool_parameters(self, xml_content: str) -> Dict[str, Any]:
        """
        è§£æå·¥å…·å‚æ•°çš„XMLå†…å®¹
        
        Args:
            xml_content: XMLå‚æ•°å†…å®¹
            
        Returns:
            è§£æå‡ºçš„å‚æ•°å­—å…¸
        """
        parameters = {}
        
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…å‚æ•°æ ‡ç­¾
        param_pattern = r'<(\w+)>(.*?)</\1>'
        matches = re.findall(param_pattern, xml_content, re.DOTALL)
        
        for param_name, param_value in matches:
            param_value = param_value.strip()
            
            # å°è¯•è§£æç‰¹æ®Šç±»å‹çš„å‚æ•°
            if param_name == 'pd_read_kwargs':
                try:
                    # å°è¯•è§£æä¸ºå­—å…¸
                    parameters[param_name] = eval(param_value) if param_value else {}
                except:
                    parameters[param_name] = {}
            else:
                parameters[param_name] = param_value
        
        return parameters
    
    def _call_model_with_retry(self, messages: List[Dict[str, Any]], max_retries: int = None, 
                             retry_delay: float = None, debug: bool = False) -> str:
        """
        å¢å¼ºçš„å¸¦é‡è¯•æœºåˆ¶çš„æ¨¡å‹è°ƒç”¨ï¼Œæ”¯æŒä¸Šä¸‹æ–‡é•¿åº¦é”™è¯¯å¤„ç†
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            retry_delay: é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰
            debug: æ˜¯å¦æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
            
        Returns:
            æ¨¡å‹å“åº”
            
        Raises:
            Exception: é‡è¯•è€—å°½åä»ç„¶å¤±è´¥
        """
        if max_retries is None:
            max_retries = self.config.max_model_retries
        if retry_delay is None:
            retry_delay = self.config.retry_delay
            
        last_error = None
        original_messages = messages.copy()
        
        for attempt in range(max_retries + 1):
            try:
                if attempt > 0:
                    self.loggers['error'].warning(f"ç¬¬ {attempt} æ¬¡é‡è¯•æ¨¡å‹è°ƒç”¨...")
                    if debug:
                        print(f"ğŸ”„ ç¬¬ {attempt} æ¬¡é‡è¯•æ¨¡å‹è°ƒç”¨...")
                    delay = self.error_handler.calculate_retry_delay(attempt, str(last_error) if last_error else "")
                    time.sleep(delay)
                
                response = self.model_client.chat(
                    messages=messages,
                    model=self.model_name,
                    temperature=self.temperature,
                    debug=debug
                )
                
                if attempt > 0:
                    self.loggers['error'].info(f"é‡è¯•æˆåŠŸï¼ˆç¬¬ {attempt} æ¬¡ï¼‰")
                    if debug:
                        print(f"âœ… é‡è¯•æˆåŠŸï¼ˆç¬¬ {attempt} æ¬¡ï¼‰")
                
                return response
                
            except Exception as e:
                last_error = e
                error_msg = str(e).lower()
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯ä¸Šä¸‹æ–‡é•¿åº¦é”™è¯¯
                if 'context length' in error_msg or 'token' in error_msg:
                    self.loggers['error'].warning(f"ä¸Šä¸‹æ–‡é•¿åº¦è¶…é™ï¼Œå°è¯•è¿›ä¸€æ­¥å‹ç¼©: {e}")
                    
                    # è¿›ä¸€æ­¥å‹ç¼©æ¶ˆæ¯
                    messages = self.context_manager.compress_for_context_limit(messages)
                    if len(messages) <= 3:
                        # å·²ç»å‹ç¼©åˆ°æœ€å°ï¼Œæ— æ³•ç»§ç»­
                        self.loggers['error'].error(f"æ— æ³•è¿›ä¸€æ­¥å‹ç¼©ä¸Šä¸‹æ–‡: {e}")
                        raise e
                    continue
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯å¯é‡è¯•çš„é”™è¯¯
                if not self.error_handler.is_retryable_error(error_msg):
                    self.loggers['error'].error(f"é‡åˆ°ä¸å¯é‡è¯•çš„é”™è¯¯: {e}")
                    raise e
                
                if attempt < max_retries:
                    self.loggers['error'].warning(f"APIè°ƒç”¨å¤±è´¥ (ç¬¬ {attempt + 1} æ¬¡å°è¯•): {e}")
                    if debug:
                        print(f"âš ï¸ APIè°ƒç”¨å¤±è´¥ (ç¬¬ {attempt + 1} æ¬¡å°è¯•): {e}")
                else:
                    self.loggers['error'].error(f"APIè°ƒç”¨é‡è¯•è€—å°½ï¼Œæœ€åé”™è¯¯: {e}")
                    if debug:
                        print(f"âŒ APIè°ƒç”¨é‡è¯•è€—å°½ï¼Œæœ€åé”™è¯¯: {e}")
        
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†
        raise last_error
    
    def diagnose_single_case(self, case: Dict[str, str], debug: bool = False) -> Dict[str, Any]:
        """
        è¯Šæ–­å•ä¸ªæ•…éšœæ¡ˆä¾‹
        
        Args:
            case: æ•…éšœæ¡ˆä¾‹ï¼ŒåŒ…å«uuidå’ŒAnomaly Description
            debug: æ˜¯å¦æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
            
        Returns:
            è¯Šæ–­ç»“æœ
        """
        uuid = case["uuid"]
        description = case["Anomaly Description"]
        
        # åˆ›å»ºæ¡ˆä¾‹ç‰¹å®šçš„é”™è¯¯æ—¥å¿—è®°å½•å™¨
        self.case_error_logger = self.logger_setup.create_case_error_logger(uuid)
        
        # è®°å½•è¯Šæ–­å¼€å§‹
        self._log_diagnosis_start(uuid, description)
        
        print(f"\nğŸ” å¼€å§‹è¯Šæ–­æ•…éšœæ¡ˆä¾‹: {uuid}")
        print(f"æè¿°: {description}")
        print("=" * 80)
        
        # é‡ç½®æ­¥éª¤è®¡æ•°
        self.steps = []
        self.current_step = 0
        
        try:
            # ä»æ•…éšœæè¿°ä¸­æå–æ—¶é—´çª—å£å¹¶å‘ç°ç›¸å…³æ–‡ä»¶
            file_info = self.file_discovery.discover_relevant_files(description, debug)
            
            # Build competition-specific task prompt
            task_prompt = f"""
<fault_case>
Please analyze the following fault case and perform root cause localization:

Fault Case UUID: {uuid}
Anomaly Description: {description}
</fault_case>

<available_data>
{file_info}
</available_data>

<analysis_requirements>
You need to complete the following analysis tasks:
1. Analyze the time window when the fault occurred
2. Systematically analyze relevant monitoring data (logs, metrics, traces)
3. Identify the root cause component
4. Determine the fault reason
5. Provide complete reasoning trace
</analysis_requirements>

<output_requirements>
Output format requirements:
- Each reasoning step must include specific action and observation
- Observation field should be limited to 100 characters, highlighting key information
- Must collect multi-dimensional evidence (metric anomalies, log errors, trace anomalies)
- Reasoning steps should be compact and efficient, avoiding redundancy
- Finally use attempt_completion to submit the result
</output_requirements>

<instructions>
Please start the analysis.
</instructions>
            """
            
            # æ„å»ºåˆå§‹æ¶ˆæ¯
            messages = [
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": task_prompt}
            ]
            
            iteration = 0
            final_result = None
            
            while iteration < self.config.max_iterations:
                iteration += 1
                self.current_step += 1
                
                self.loggers['diagnosis'].info(f"ç¬¬ {iteration} è½®æ¨ç†å¼€å§‹...")
                
                if debug:
                    print(f"\nğŸ”„ ç¬¬ {iteration} è½®æ¨ç†...")
                
                try:
                    # ä¸Šä¸‹æ–‡ç®¡ç† - åœ¨è°ƒç”¨æ¨¡å‹å‰è¿›è¡Œä¸Šä¸‹æ–‡é•¿åº¦æ£€æŸ¥å’Œå‹ç¼©
                    managed_messages = self.context_manager.manage_context_length(messages)
                    
                    # è®°å½•æ¨¡å‹äº¤äº’
                    self._log_model_interaction(iteration, len(managed_messages), 0)
                    
                    # è®°å½•LLMè°ƒç”¨å¼€å§‹æ—¶é—´
                    llm_start_time = datetime.now()
                    
                    # ä½¿ç”¨å¸¦é‡è¯•æœºåˆ¶çš„æ¨¡å‹è°ƒç”¨
                    response = self._call_model_with_retry(
                        messages=managed_messages,
                        debug=debug
                    )
                    
                    # è®¡ç®—LLMè°ƒç”¨è€—æ—¶
                    llm_duration = (datetime.now() - llm_start_time).total_seconds()
                    
                    # è®°å½•LLMåŸå§‹äº¤äº’ä¿¡æ¯
                    self._log_llm_interaction(
                        iteration=iteration,
                        uuid=uuid,
                        input_messages=managed_messages,
                        output_response=response,
                        duration=llm_duration,
                        model_name=self.model_name
                    )
                    
                    # æ›´æ–°äº¤äº’æ—¥å¿—ï¼ˆä¼ å…¥å®Œæ•´å“åº”ï¼‰
                    self._log_model_interaction(iteration, len(messages), len(response), response)
                    
                    # å®Œæ•´å“åº”è®°å½•åˆ°äº¤äº’æ—¥å¿— - æ— è®ºæ˜¯å¦debugéƒ½è®°å½•
                    self.loggers['interaction'].debug(f"å®Œæ•´æ¨¡å‹å“åº”:\n{response}")
                    
                    if debug:
                        print(f"ğŸ“ æ¨¡å‹å“åº”é¢„è§ˆ:\n{response[:500]}{'...' if len(response) > 500 else ''}\n")
                    
                    # è§£æå·¥å…·è°ƒç”¨
                    tool_calls = self.parse_xml_tool_calls(response)
                    
                    if not tool_calls:
                        warning_msg = "æœªæ£€æµ‹åˆ°å·¥å…·è°ƒç”¨ï¼Œä»»åŠ¡å¯èƒ½å·²å®Œæˆæˆ–å­˜åœ¨é—®é¢˜"
                        self.loggers['diagnosis'].warning(warning_msg)
                        self.loggers['interaction'].warning(warning_msg)  # ä¹Ÿè®°å½•åˆ°äº¤äº’æ—¥å¿—
                        if debug:
                            print(f"âŒ {warning_msg}")
                        break
                    
                    # æ‰§è¡Œå·¥å…·è°ƒç”¨
                    tool_results = []
                    for tool_call in tool_calls:
                        # å§‹ç»ˆè®°å½•å·¥å…·æ‰§è¡Œåˆ°æ—¥å¿— - æ— è®ºæ˜¯å¦debug
                        self.loggers['interaction'].info(f"æ‰§è¡Œå·¥å…·: {tool_call.name}")
                        self.loggers['interaction'].info(f"å·¥å…·å‚æ•°: {json.dumps(tool_call.parameters, ensure_ascii=False)}")
                        
                        if debug:
                            print(f"ğŸ”§ æ‰§è¡Œå·¥å…·: {tool_call.name}")
                        
                        result = self.tool_executor.execute_tool(tool_call, self.case_error_logger)
                        tool_results.append((tool_call, result))
                        
                        # è®°å½•æ‰§è¡Œæ­¥éª¤ - ä¿å­˜å®Œæ•´ä¿¡æ¯ç”¨äºè¯¦ç»†æ—¥å¿—
                        full_observation = str(result)
                        full_reasoning = response
                        
                        step = AgentStep(
                            step_num=self.current_step,
                            action=f"{tool_call.name}({json.dumps(tool_call.parameters, ensure_ascii=False)})",
                            observation=full_observation,  # ä¿å­˜å®Œæ•´è§‚å¯Ÿä¿¡æ¯
                            reasoning=full_reasoning       # ä¿å­˜å®Œæ•´æ¨ç†ä¿¡æ¯
                        )
                        self.steps.append(step)
                        
                        # ä¼ é€’å®Œæ•´ä¿¡æ¯ç»™æ—¥å¿—è®°å½•æ–¹æ³•
                        self._log_diagnosis_step(self.current_step, step.action, full_observation, full_reasoning)
                        
                        # é¢å¤–è®°å½•å·¥å…·æ‰§è¡Œçš„è¯¦ç»†ä¿¡æ¯
                        self.loggers['tool'].info(f"å·¥å…·æ‰§è¡Œ: {tool_call.name}")
                        self.loggers['tool'].info(f"å‚æ•°: {json.dumps(tool_call.parameters, ensure_ascii=False, indent=2)}")
                        self.loggers['tool'].info(f"ç»“æœé•¿åº¦: {len(full_observation)} å­—ç¬¦")
                        self.loggers['tool'].info(f"ç»“æœå†…å®¹:\n{full_observation}")
                        self.loggers['tool'].info("=" * 60)
                        
                        # æ£€æŸ¥æ˜¯å¦å®Œæˆä»»åŠ¡
                        if tool_call.name == "attempt_completion" and "status" in result:
                            if result["status"] == "completed":
                                final_result = result.get("result")
                                completion_msg = "æ•…éšœè¯Šæ–­æˆåŠŸå®Œæˆ!"
                                self.loggers['diagnosis'].info(completion_msg)
                                self.loggers['interaction'].info(completion_msg)  # ä¹Ÿè®°å½•åˆ°äº¤äº’æ—¥å¿—
                                if debug:
                                    print("âœ… æ•…éšœè¯Šæ–­å®Œæˆ!")
                                return {
                                    "status": "completed",
                                    "result": final_result,
                                    "steps": self.steps,
                                    "iterations": iteration
                                }
                            else:
                                error_msg = f"ä»»åŠ¡å®Œæˆè°ƒç”¨å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"
                                self.loggers['diagnosis'].error(error_msg)
                                self.loggers['interaction'].error(error_msg)  # ä¹Ÿè®°å½•åˆ°äº¤äº’æ—¥å¿—
                                if self.case_error_logger:
                                    self.case_error_logger.error(error_msg)
                                if debug:
                                    print(f"âš ï¸ {error_msg}")
                    
                    # å°†å·¥å…·ç»“æœæ·»åŠ åˆ°å¯¹è¯å†å²
                    tool_results_text = "\n".join([
                        self.tool_executor.format_tool_result(tool_call, result) 
                        for tool_call, result in tool_results
                    ])
                    
                    messages.append({"role": "assistant", "content": response})
                    messages.append({"role": "user", "content": f"Tool execution results:\n{tool_results_text}\nContinue analysis."})
                    
                except Exception as e:
                    error_msg = f"ç¬¬ {iteration} è½®æ‰§è¡Œå‡ºé”™: {e}"
                    self.loggers['diagnosis'].error(error_msg)
                    self.loggers['interaction'].error(error_msg)  # ä¹Ÿè®°å½•åˆ°äº¤äº’æ—¥å¿—
                    self.error_handler.log_error_with_context(e, f"ç¬¬ {iteration} è½®æ‰§è¡Œ", uuid, self.case_error_logger)
                    if debug:
                        print(f"âŒ {error_msg}")
                    else:
                        print("âŒ", end="", flush=True)
                    
                    # æ— è®ºæ˜¯å¦debugéƒ½è®°å½•å®Œæ•´å¼‚å¸¸ä¿¡æ¯åˆ°æ—¥å¿—
                    import traceback
                    full_traceback = traceback.format_exc()
                    self.loggers['interaction'].debug(f"å®Œæ•´å¼‚å¸¸å †æ ˆ:\n{full_traceback}")
                    
                    if debug:
                        traceback.print_exc()
                    
                    # å¦‚æœæ˜¯æ—©æœŸé”™è¯¯ï¼ˆå‰3è½®ï¼‰ï¼Œå°è¯•ç»§ç»­
                    if iteration <= 3:
                        continue_msg = "æ—©æœŸé”™è¯¯ï¼Œå°è¯•ç»§ç»­æ‰§è¡Œ..."
                        self.loggers['diagnosis'].warning(continue_msg)
                        self.loggers['interaction'].warning(continue_msg)
                        continue
                    else:
                        break
            
            # è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°æˆ–å…¶ä»–åŸå› ç»“æŸ
            result_summary = {
                "status": "incomplete",
                "result": final_result,
                "steps": self.steps,
                "iterations": iteration,
                "reason": "è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°" if iteration >= self.config.max_iterations else "æ‰§è¡Œä¸­æ–­"
            }
            
            self.loggers['diagnosis'].warning(f"è¯Šæ–­æœªå®Œæˆ: {result_summary['reason']}")
            return result_summary
            
        except Exception as e:
            self.error_handler.log_error_with_context(e, "è¯Šæ–­å•ä¸ªæ¡ˆä¾‹", uuid, self.case_error_logger)
            return {
                "status": "error", 
                "error": str(e),
                "steps": self.steps,
                "iterations": 0
            }
    
    def process_input_json(self, input_file: str = "input.json", output_file: str = "answer.json", debug: bool = False) -> Dict[str, Any]:
        """
        å¤„ç†input.jsonæ–‡ä»¶ä¸­çš„æ‰€æœ‰æ•…éšœæ¡ˆä¾‹ï¼Œç”Ÿæˆanswer.json
        
        Args:
            input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            debug: æ˜¯å¦æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
            
        Returns:
            å¤„ç†ç»“æœç»Ÿè®¡
        """
        print(f"ğŸš€ å¼€å§‹å¤„ç†æ•…éšœæ¡ˆä¾‹")
        if debug:
            print(f"è¾“å…¥æ–‡ä»¶: {input_file}")
            print(f"è¾“å‡ºæ–‡ä»¶: {output_file}")
            print("=" * 80)
        
        self.loggers['summary'].info("=" * 80)
        self.loggers['summary'].info("å¼€å§‹å¤„ç† CCF AIOps æŒ‘æˆ˜èµ›æ•…éšœæ¡ˆä¾‹")
        self.loggers['summary'].info(f"è¾“å…¥æ–‡ä»¶: {input_file}")
        self.loggers['summary'].info(f"è¾“å‡ºæ–‡ä»¶: {output_file}")
        self.loggers['summary'].info("=" * 80)
        
        # è¯»å–è¾“å…¥æ–‡ä»¶
        try:
            with open(input_file, 'r', encoding='utf-8') as f:
                cases = json.load(f)
        except Exception as e:
            error_msg = f"è¯»å–è¾“å…¥æ–‡ä»¶å¤±è´¥: {e}"
            print(f"âŒ è¯»å–è¾“å…¥æ–‡ä»¶å¤±è´¥")
            self.loggers['summary'].error(error_msg)
            self.error_handler.log_error_with_context(e, "è¯»å–è¾“å…¥æ–‡ä»¶")
            return {"status": "error", "error": str(e)}
        
        print(f"ğŸ“Š å…± {len(cases)} ä¸ªæ¡ˆä¾‹")
        self.loggers['summary'].info(f"å…±å‘ç° {len(cases)} ä¸ªæ•…éšœæ¡ˆä¾‹")
        
        # å¤„ç†æ‰€æœ‰æ¡ˆä¾‹
        results = []
        successful_count = 0
        failed_count = 0
        
        for i, case in enumerate(cases):
            try:
                if debug:
                    print(f"\n{'='*80}")
                    print(f"è¿›åº¦: {i+1}/{len(cases)} - {(i+1)/len(cases)*100:.1f}%")
                else:
                    print(f"å¤„ç†æ¡ˆä¾‹ {i+1}/{len(cases)}", end=" ", flush=True)
                
                self.loggers['summary'].info(f"å¤„ç†æ¡ˆä¾‹ {i+1}/{len(cases)}: {case.get('uuid', 'unknown')}")
                
                # è¯Šæ–­å•ä¸ªæ¡ˆä¾‹
                diagnosis_result = self.diagnose_single_case(case, debug=debug)
                
                if diagnosis_result["status"] == "completed" and diagnosis_result["result"]:
                    results.append(diagnosis_result["result"])
                    successful_count += 1
                    success_msg = f"æ¡ˆä¾‹ {case['uuid']} è¯Šæ–­å®Œæˆ"
                    if debug:
                        print(f"âœ… {success_msg}")
                    else:
                        print("âœ…")
                    self.loggers['summary'].info(success_msg)
                else:
                    failed_count += 1
                    fail_msg = f"æ¡ˆä¾‹ {case['uuid']} è¯Šæ–­å¤±è´¥: {diagnosis_result.get('reason', 'æœªçŸ¥åŸå› ')}"
                    if debug:
                        print(f"âŒ {fail_msg}")
                    else:
                        print("âŒ")
                    self.loggers['summary'].error(fail_msg)
                    
                    # ä¸ºå¤±è´¥çš„æ¡ˆä¾‹ç”Ÿæˆä¸€ä¸ªåŸºæœ¬ç»“æœï¼Œé¿å…ä¸¢å¤±
                    fallback_result = {
                        "uuid": case["uuid"],
                        "component": "unknown",
                        "reason": "analysis_failed", 
                        "time": "2025-06-06 12:00:00",
                        "reasoning_trace": [
                            {
                                "step": 1,
                                "action": "DiagnosisAttempt",
                                "observation": "Automatic diagnosis failed, requires manual investigation"
                            }
                        ]
                    }
                    results.append(fallback_result)
                
            except Exception as e:
                error_msg = f"å¤„ç†æ¡ˆä¾‹ {case.get('uuid', 'unknown')} æ—¶å‡ºé”™: {e}"
                if debug:
                    print(f"âŒ {error_msg}")
                else:
                    print("âŒ")
                self.loggers['summary'].error(error_msg)
                self.loggers['interaction'].error(error_msg)  # ä¹Ÿè®°å½•åˆ°äº¤äº’æ—¥å¿—
                self.error_handler.log_error_with_context(e, f"å¤„ç†æ¡ˆä¾‹ {case.get('uuid', 'unknown')}")
                failed_count += 1
                
                # æ— è®ºæ˜¯å¦debugéƒ½è®°å½•å®Œæ•´å¼‚å¸¸ä¿¡æ¯åˆ°æ—¥å¿—
                import traceback
                full_traceback = traceback.format_exc()
                self.loggers['interaction'].debug(f"å¤„ç†æ¡ˆä¾‹å¼‚å¸¸å †æ ˆ:\n{full_traceback}")
                
                if debug:
                    traceback.print_exc()
        
        # ä¿å­˜ç»“æœ
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            save_msg = f"ç»“æœå·²ä¿å­˜åˆ° {output_file}"
            if debug:
                print(f"\nâœ… {save_msg}")
            else:
                print(f"\nâœ… å·²ä¿å­˜åˆ° {output_file}")
            self.loggers['summary'].info(save_msg)
        except Exception as e:
            error_msg = f"ä¿å­˜ç»“æœå¤±è´¥: {e}"
            if debug:
                print(f"âŒ {error_msg}")
            else:
                print(f"âŒ ä¿å­˜å¤±è´¥")
            self.loggers['summary'].error(error_msg)
            self.error_handler.log_error_with_context(e, "ä¿å­˜ç»“æœ")
            return {"status": "error", "error": f"ä¿å­˜å¤±è´¥: {str(e)}"}
        
        # è¿”å›ç»Ÿè®¡ç»“æœ
        summary = {
            "status": "completed",
            "total_cases": len(cases),
            "successful_cases": successful_count,
            "failed_cases": failed_count,
            "success_rate": successful_count / len(cases) * 100,
            "output_file": output_file
        }
        
        if debug:
            print(f"\n{'='*80}")
            print(f"ğŸ“Š å¤„ç†å®Œæˆç»Ÿè®¡:")
            print(f"æ€»æ¡ˆä¾‹æ•°: {summary['total_cases']}")
            print(f"æˆåŠŸæ¡ˆä¾‹: {summary['successful_cases']}")
            print(f"å¤±è´¥æ¡ˆä¾‹: {summary['failed_cases']}")
            print(f"æˆåŠŸç‡: {summary['success_rate']:.1f}%")
            print(f"{'='*80}")
        else:
            print(f"\nğŸ“Š å®Œæˆ: æˆåŠŸ{summary['successful_cases']}/{summary['total_cases']} ({summary['success_rate']:.1f}%)")
        
        # è®°å½•æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯
        self.loggers['summary'].info("=" * 80)
        self.loggers['summary'].info("å¤„ç†å®Œæˆç»Ÿè®¡:")
        self.loggers['summary'].info(f"æ€»æ¡ˆä¾‹æ•°: {summary['total_cases']}")
        self.loggers['summary'].info(f"æˆåŠŸæ¡ˆä¾‹: {summary['successful_cases']}")
        self.loggers['summary'].info(f"å¤±è´¥æ¡ˆä¾‹: {summary['failed_cases']}")
        self.loggers['summary'].info(f"æˆåŠŸç‡: {summary['success_rate']:.1f}%")
        self.loggers['summary'].info("=" * 80)
        
        return summary 